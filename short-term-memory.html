---
active_crumb: Shot-Term Memory
layout: documentation
id: short_term_memory
---

<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<div id="short-term-memory" class="col-md-8 second-column">
    <section id="stm">
        <h2 class="section-title">Conversation <span class="amp">&</span> STM <a href="#"><i class="top-link fas fa-fw fa-angle-double-up"></i></a></h2>
        <div class="bq info">
            <b>Short-Term Memory</b>
            <p>
                Read more in-depth explanation about maintaining conversational context and
                Short-Term Memory in this <a href="/blogs/short_term_memory.html">blog.</a>
            </p>
        </div>

        <p>
            NLPCraft provides automatic conversation management right out of the box.
            Conversation management is based on the idea of short-term memory (STM). STM is automatically
            maintained by NLPCraft per each user and data model. Essentially, NLPCraft "remembers"
            the context of the conversation and can supply the currently missing elements from its memory (i.e. from STM).
            STM implementation is also fully integrated with intent matching.
        </p>
        <p>
            Maintaining conversation state is necessary for effective context resolution, so that users
            could ask, for example, the following sequence of questions using example weather model:
        </p>
        <dl class="stm-example">
            <dd><i class="fa fa-fw fa-angle-right"></i>What’s the weather in London today?</dd>
            <dt>
                <p>
                    User gets the current London’s weather.
                    STM is empty at this moment so NLPCraft expects to get all necessary information from
                    the user sentence. Meaningful parts of the sentence get stored in STM.
                </p>
                <div class="stm-state">
                    <div class="stm">
                        <label>STM Before:</label>
                        <span>&nbsp;</span>
                    </div>
                    <div class="stm">
                        <label>STM After:</label>
                        <span>weather</span>
                        <span>London</span>
                        <span>today</span>
                    </div>
                </div>
            </dt>
            <dd><i class="fa fa-fw fa-angle-right"></i>And what about Berlin?</dd>
            <dt>
                <p>
                    User gets the current Berlin’s weather.
                    The only useful data in the user sentence is name of the city <code>Berlin</code>. But since
                    NLPCraft now has data from the previous question in its STM it can safely deduce that we
                    are asking about <code>weather</code> for <code>today</code>.
                    <code>Berlin</code> overrides <code>London</code> in STM.
                </p>
                <div class="stm-state">
                    <div class="stm">
                        <label>STM Before:</label>
                        <span>weather</span>
                        <span>London</span>
                        <span>today</span>
                    </div>
                    <div class="stm">
                        <label>STM After:</label>
                        <span>weather</span>
                        <span><b>Berlin</b></span>
                        <span>today</span>
                    </div>
                </div>
            </dt>
            <dd><i class="fa fa-fw fa-angle-right"></i>Next week forecast?</dd>
            <dt>
                <p>
                    User gets the next week forecast for Berlin.
                    Again, the only useful data in the user sentence is <code>next week</code> and <code>forecast</code>.
                    STM supplies <code>Berlin</code>. <code>Next week</code> override <code>today</code>, and
                    <code>forecast</code> override <code>weather</code> in STM.
                </p>
                <div class="stm-state">
                    <div class="stm">
                        <label>STM Before:</label>
                        <span>weather</span>
                        <span>Berlin</span>
                        <span>today</span>
                    </div>
                    <div class="stm">
                        <label>STM After:</label>
                        <span><b>forecast</b></span>
                        <span>Berlin</span>
                        <span><b>Next week</b></span>
                    </div>
                </div>
            </dt>
        </dl>
        <p>
            Note that STM is maintained per user and per data model.
            Conversation management implementation is also smart enough to clear STM after certain
            period of time, i.e. it “forgets” the conversational context after few minutes of inactivity.
            Note also that conversational context can also be cleared explicitly
            via <a href="https://github.com/apache/incubator-nlpcraft/blob/master/openapi/nlpcraft_swagger.yml" target="github">REST API</a>.
        </p>
    </section>
</div>
<div class="col-md-2 third-column">
    <ul class="side-nav">
        <li class="side-nav-title">On This Page</li>
        {% include quick-links.html %}
    </ul>
</div>
