---
active_crumb: Short-Term Memory
layout: blog
blog_title: Short-Term Memory - Maintaining Conversation Context
author_name: Aaron Radzinski
author_avatar: images/lion.jpg
author_linkedin_id: aaron-radzinski-6b2228167
author_twitter_id: aaron_radzinski
author_medium_id: aradzinski
publish_date: July 26, 2019
---

<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<section id="">
    <p>
        <img alt="" class="img-fluid" src="/images/stm1.png">
    </p>
    <p>
        In this blog, I’ll try to give a high-level overview of STM - Short-Term Memory, a technique used to
        maintain conversational context in NLPCraft. Maintaining the proper conversation context - remembering
        what the current conversation is about - is essential for all human interaction and thus essential for
        computer-based natural language understanding. To my knowledge, NLPCraft provides one of the most advanced
        implementations of STM, especially considering how tightly it is integrated with NLPCraft’s unique
        intent-based matching (Google’s <a target=google href="https://cloud.google.com/dialogflow/">DialogFlow</a> is very similar yet).
    </p>
    <p>
        Let’s dive in.
    </p>
</section>
<section>
    <h2 class="section-title">Parsing User Input</h2>
    <p>
        One of the key objectives when parsing user input sentence for Natural Language Understanding (NLU) is to
        detect all possible semantic entities, a.k.a <em>named entities</em>. Let’s consider a few examples:
    </p>
    <ul>
        <li>
            <code>"What’s the current weather in Tokyo?"</code><br/>
            This sentence is fully sufficient for the processing
            since it contains the topic <code>weather</code> as well as all necessary parameters
            like time (<code>current</code>) and location (<code>Tokyo</code>).
        </li>
        <li>
            <code>"What about Tokyo?"</code><br/>
            This is an unclear sentence since it does not have the subject of the
            question - what is it about Tokyo?
        </li>
        <li>
            <code>"What’s the weather?"</code><br/>
            This is also unclear since we are missing important parameters
            of location and time for our request.
        </li>
    </ul>
    <p>
        Sometimes we can use default values like the current user’s location and the current time (if they are missing).
        However, this can easily lead to the wrong interpretation if the conversation has an existing context.
    </p>
    <p>
        In real life, as well as in NLP-based systems, we always try to start a conversation with a fully defined
        sentence since without a context the missing information cannot be obtained and the sentenced cannot be interpreted.
    </p>
</section>
<section>
    <h2 class="section-title">Semantic Entities</h2>
    <p>
        Let’s take a closer look at the named entities from the above examples:
    </p>
    <ul>
        <li>
            <code>weather</code> - this is an indicator of the subject of the conversation. Note that it indicates
            the type of question rather than being an entity with multiple possible values.
        </li>
        <li>
            <code>current</code> - this is an entity of type <code>Date</code> with the value of <code>now</code>.
        </li>
        <li>
            <code>Tokyo</code> - this is an entity of type <code>Location</code> with two values:
            <ul>
                <li><code>city</code> - type of the location.</li>
                <li><code>Tokyo, Japan</code> - normalized name of the location.</li>
            </ul>
        </li>
    </ul>
    <p>
        We have two distinct classes of entities:
    </p>
    <ul>
        <li>
            Entities that have no values and only act as indicators or types. The entity <code>weather</code> is the
            type indicator for the subject of the user input.
        </li>
        <li>
            Entities that additionally have one or more specific values like <code>current</code> and <code>Tokyo</code> entities.
        </li>
    </ul>
    <div class="bq success">
        <div style="display: inline-block; margin-bottom: 20px">
            <a style="margin-right: 10px" target="opennlp" href="https://opennlp.apache.org"><img src="/images/opennlp-logo.png" height="32px" alt=""></a>
            <a style="margin-right: 10px" target="google" href="https://cloud.google.com/natural-language/"><img src="/images/google-cloud-logo-small.png" height="32px" alt=""></a>
            <a style="margin-right: 10px" target="stanford" href="https://stanfordnlp.github.io/CoreNLP"><img src="/images/corenlp-logo.gif" height="48px" alt=""></a>
            <a style="margin-right: 10px" target="spacy" href="https://spacy.io"><img src="/images/spacy-logo.png" height="32px" alt=""></a>
        </div>
        <p>
            Note that NLPCraft provides <a href="/integrations.html">support</a> for wide variety of named entities (with all built-in ones being properly normalized)
            including  <a href="/integrations.html">integrations</a> with
            <a target="spacy" href="https://spacy.io/">spaCy</a>,
            <a target="stanford" href="https://stanfordnlp.github.io/CoreNLP">Stanford CoreNLP</a>,
            <a target="opennlp" href="https://opennlp.apache.org/">OpenNLP</a> and
            <a target="google" href="https://cloud.google.com/natural-language/">Google Natural Language</a>.
        </p>
    </div>
</section>
<section>
    <h2 class="section-title">Incomplete Sentences</h2>
    <p>
        Assuming previously asked questions about the weather in Tokyo (in the span of the ongoing conversation) one
        could presumably ask the following questions using a <em>shorter, incomplete</em>, form:
    </p>
    <ul>
        <li>
            <code>"What about Kyoto?</code><br/>
            This question is missing both the subject and the time. However, we
            can safely assume we are still talking about current weather.
        </li>
        <li>
            <code>"What about tomorrow?"</code><br/>
            Just like above we automatically assume the weather subject but
            use <code>Kyoto</code> as the location since it was mentioned the last.
        </li>
    </ul>
    <p>
        These are incomplete sentences. This type of short-hands cannot be interpreted without prior context (neither
        by humans or by machines) since by themselves they are missing necessary information.
        In the context of the conversation, however, these incomplete sentences work. We can simply provide one or two
        entities and rely on the <em>"listener"</em> to recall the rest of missing information from a
        <em>short-term memory</em>, a.k.a conversation context.
    </p>
    <p>
        In NLPCraft, the intent-matching logic will automatically try to find missing information in the
        conversation context (that is automatically maintained). Moreover, it will properly treat such recalled
        information during weighted intent matching since it naturally has less "weight" than something that was
        found explicitly in the user input.
    </p>
</section>
<section>
    <h2 class="section-title">Short-Term Memory</h2>
    <p>
        The short-term memory is exactly that... a memory that keeps only small amount of recently used information
        and that evicts its contents after a short period of inactivity.
    </p>
    <p>
        Let’s look at the example from a real life. If you would call your friend in a couple of hours asking <code>"What about a day after?"</code>
        (still talking about weather in Kyoto) - he’ll likely be thoroughly confused. The conversation is timed out, and
        your friend has lost (forgotten) its context. You will have to explain again to your confused friend what is that you are asking about...
    </p>
    <p>
        NLPCraft has a simple rule that 5 minutes pause in conversation leads to the conversation context reset. However,
        what happens if we switch the topic before this timeout elapsed?
    </p>
</section>
<section>
    <h2 class="section-title">Context Switch</h2>
    <p>
        Resetting the context by the timeout is, obviously, not a hard thing to do. What can be trickier is to detect
        when conversation topic is switched and the previous context needs to be forgotten to avoid very
        confusing interpretation errors. It is uncanny how humans can detect such switch with seemingly no effort, and yet
        automating this task by the computer is anything but effortless...
    </p>
    <p>
        Let’s continue our weather-related conversation. All of a sudden, we ask about something completely different:
    </p>
    <ul>
        <li>
            <code>"How much mocha latter at Starbucks?"</code><br/>
            At this point we should forget all about previous conversation about weather and assume going forward
            that we are talking about coffee in Starbucks.
        </li>
        <li>
            <code>"What about Peet’s?"</code><br/>
            We are talking about latter at Peet’s.
        </li>
        <li>
            <code>"...and croissant?"</code><br/>
            Asking about Peet’s crescent-shaped fresh rolls.
        </li>
    </ul>
    <p>
        Despite somewhat obvious logic the implementation of context switch is not an exact science. Sometimes, you
        can have a "soft" context switch where you don’t change the topic of the conversation 100% but yet sufficiently
        enough to forget at least some parts of the previously collected context. NLPCraft has a built-in algorithm
        to detect the hard switch in the conversation. It also exposes API to perform a selective reset on the
        conversation in case of “soft” switch.
    </p>
</section>


